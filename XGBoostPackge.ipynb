{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiguo\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\jiguo\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import log_loss, mean_squared_error as mse, r2_score \n",
    "from sklearn.metrics.scorer import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runXGB(X_train, y_train, X_test=None, num_class=1, feature_names=None, seed=0, num_rounds=100, early_stopping_rounds=50):\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear', #'multi:softprob'\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'num_class' : num_class,\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'seed': seed,\n",
    "    'silent': 0,\n",
    "    'eval_metric': 'rmse' # \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "    }\n",
    "\n",
    "    plst = list(params.items())\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    model = xgb.train(plst, dtrain, num_boost_round=num_rounds, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    if X_test is not None:\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        pred = model.predict(dtest)\n",
    "        return pred, model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGBTest(X_train, y_train=None, X_test, feature_names=None, seed=0, num_rounds=1000, test_size=.3, \\\n",
    "               early_stopping_rounds=50):\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear', #'multi:softprob'\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.85, #like max_features\n",
    "    'num_class' = 1,\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'seed': seed,\n",
    "    'silent': 0,\n",
    "    'eval_metric': 'rmse' # \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "    }\n",
    "\n",
    "    plst = list(params.items())\n",
    "    X_dtrain, X_deval, y_dtrain, y_deval=train_test_split(X_train, y_train, random_state=seed, test_size=test_size)\n",
    "    dtrain = xgb.DMatrix(X_dtrain, y_dtrain)\n",
    "    deval = xgb.DMatrix(X_deval, y_deval)\n",
    "    watchlist = [(deval, 'eval')]\n",
    "    \n",
    "    model = xgb.train(plst, dtrain, num_rounds, watchlist, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    if X_test is not None:\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        pred = model.predict(dtest)\n",
    "        return pred, model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class xgbClass(object):\n",
    "    def __init__(self, eta=.1, subsample=.8, num_class=1, max_depth=5, seed=17, silent=0, eva_metric='mlogloss',\\\n",
    "                colsample_bytree=.8, objective='solfprob'):\n",
    "        self.params={\n",
    "        'objective' : objective, #'reg:linear','multi:softprob'\n",
    "        'subsample' : subsample,\n",
    "        'colsample_bytree' : colsample_bytree, #like max_features\n",
    "        'num_class' : num_class,\n",
    "        'eta': eta,\n",
    "        'max_depth': max_depth,\n",
    "        'seed': seed,\n",
    "        'silent': silent,\n",
    "        'eval_metric': eva_metric#'rmse' \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "        }\n",
    "        self.model=[]\n",
    "        \n",
    "    def train(X_train, y_train):\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        self.model = xgb.train(self.params, dtrain, num_boost_round=num_rounds, early_stopping_rounds=early_stopping_rounds)\n",
    "    \n",
    "    def predict(X_test):\n",
    "        self.model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kagglegym\n",
    "env = kagglegym.make()\n",
    "o = env.reset()\n",
    "excl = [env.ID_COL_NAME, env.SAMPLE_COL_NAME, env.TARGET_COL_NAME, env.TIME_COL_NAME]\n",
    "col = [c for c in o.train.columns if c not in excl]\n",
    "\n",
    "O = pd.read_hdf('../input/train.h5')\n",
    "d_mean= O[col].median(axis=0)\n",
    "\n",
    "ymean_dict = dict(o.train.groupby([\"id\"])[\"y\"].median())\n",
    "\n",
    "X_train=(O[col])[O.timestamp <= 905]\n",
    "y_train=O.y[O.timestamp <= 905]\n",
    "X_test=(O[col])[O.timestamp > 905]\n",
    "y_test=O.y[O.timestamp > 905]\n",
    "X_train=X_train.fillna(d_mean)\n",
    "X_test=X_test.fillna(d_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-09dcf4c8aeac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrunXGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#-44.5409187933\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1d7c29c03aae>\u001b[0m in \u001b[0;36mrunXGB\u001b[1;34m(X_train, y_train, X_test, num_class, feature_names, seed, num_rounds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jiguo\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jiguo\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     97\u001b[0m                                \u001b[0mend_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                                evaluation_result_list=evaluation_result_list))\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mEarlyStopException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jiguo\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\callback.pyc\u001b[0m in \u001b[0;36mcallback\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;34m\"\"\"internal function\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pred, model=runXGB(X_train=X_train, y_train=y_train, X_test=X_test, num_rounds=500)\n",
    "print(r2_score(pred, y_test))\n",
    "#-44.5409187933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.475282\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[1]\teval-rmse:0.451571\n",
      "[2]\teval-rmse:0.429047\n",
      "[3]\teval-rmse:0.407654\n",
      "[4]\teval-rmse:0.387334\n",
      "[5]\teval-rmse:0.368031\n",
      "[6]\teval-rmse:0.349697\n",
      "[7]\teval-rmse:0.332282\n",
      "[8]\teval-rmse:0.315744\n",
      "[9]\teval-rmse:0.300037\n",
      "[10]\teval-rmse:0.285118\n",
      "[11]\teval-rmse:0.27095\n",
      "[12]\teval-rmse:0.257495\n",
      "[13]\teval-rmse:0.244718\n",
      "[14]\teval-rmse:0.232583\n",
      "[15]\teval-rmse:0.221062\n",
      "[16]\teval-rmse:0.210122\n",
      "[17]\teval-rmse:0.199734\n",
      "[18]\teval-rmse:0.189872\n",
      "[19]\teval-rmse:0.180509\n",
      "[20]\teval-rmse:0.171622\n",
      "[21]\teval-rmse:0.163186\n",
      "[22]\teval-rmse:0.15518\n",
      "[23]\teval-rmse:0.147581\n",
      "[24]\teval-rmse:0.14037\n",
      "[25]\teval-rmse:0.133526\n",
      "[26]\teval-rmse:0.127036\n",
      "[27]\teval-rmse:0.120879\n",
      "[28]\teval-rmse:0.115039\n",
      "[29]\teval-rmse:0.109503\n",
      "[30]\teval-rmse:0.104253\n",
      "[31]\teval-rmse:0.099277\n",
      "[32]\teval-rmse:0.094563\n",
      "[33]\teval-rmse:0.090098\n",
      "[34]\teval-rmse:0.085867\n",
      "[35]\teval-rmse:0.081861\n",
      "[36]\teval-rmse:0.078069\n",
      "[37]\teval-rmse:0.074482\n",
      "[38]\teval-rmse:0.07109\n",
      "[39]\teval-rmse:0.067881\n",
      "[40]\teval-rmse:0.06485\n",
      "[41]\teval-rmse:0.061986\n",
      "[42]\teval-rmse:0.059284\n",
      "[43]\teval-rmse:0.056735\n",
      "[44]\teval-rmse:0.054331\n",
      "[45]\teval-rmse:0.052067\n",
      "[46]\teval-rmse:0.049936\n",
      "[47]\teval-rmse:0.047931\n",
      "[48]\teval-rmse:0.046046\n",
      "[49]\teval-rmse:0.044275\n",
      "[50]\teval-rmse:0.042614\n",
      "[51]\teval-rmse:0.041058\n",
      "[52]\teval-rmse:0.0396\n",
      "[53]\teval-rmse:0.038238\n",
      "[54]\teval-rmse:0.036965\n",
      "[55]\teval-rmse:0.035777\n",
      "[56]\teval-rmse:0.03467\n",
      "[57]\teval-rmse:0.03364\n",
      "[58]\teval-rmse:0.032682\n",
      "[59]\teval-rmse:0.031792\n",
      "[60]\teval-rmse:0.030966\n",
      "[61]\teval-rmse:0.030202\n",
      "[62]\teval-rmse:0.029496\n",
      "[63]\teval-rmse:0.028842\n",
      "[64]\teval-rmse:0.02824\n",
      "[65]\teval-rmse:0.027686\n",
      "[66]\teval-rmse:0.027176\n",
      "[67]\teval-rmse:0.026708\n",
      "[68]\teval-rmse:0.026278\n",
      "[69]\teval-rmse:0.025883\n",
      "[70]\teval-rmse:0.025521\n",
      "[71]\teval-rmse:0.02519\n",
      "[72]\teval-rmse:0.024888\n",
      "[73]\teval-rmse:0.024612\n",
      "[74]\teval-rmse:0.024359\n",
      "[75]\teval-rmse:0.024128\n",
      "[76]\teval-rmse:0.023919\n",
      "[77]\teval-rmse:0.023728\n",
      "[78]\teval-rmse:0.023554\n",
      "[79]\teval-rmse:0.023396\n",
      "[80]\teval-rmse:0.023253\n",
      "[81]\teval-rmse:0.023123\n",
      "[82]\teval-rmse:0.023005\n",
      "[83]\teval-rmse:0.022898\n",
      "[84]\teval-rmse:0.0228\n",
      "[85]\teval-rmse:0.022711\n",
      "[86]\teval-rmse:0.022631\n",
      "[87]\teval-rmse:0.02256\n",
      "[88]\teval-rmse:0.022494\n",
      "[89]\teval-rmse:0.022435\n",
      "[90]\teval-rmse:0.022382\n",
      "[91]\teval-rmse:0.022334\n",
      "[92]\teval-rmse:0.022291\n",
      "[93]\teval-rmse:0.022252\n",
      "[94]\teval-rmse:0.022216\n",
      "[95]\teval-rmse:0.022184\n",
      "[96]\teval-rmse:0.022154\n",
      "[97]\teval-rmse:0.022127\n",
      "[98]\teval-rmse:0.022103\n",
      "[99]\teval-rmse:0.022081\n",
      "[100]\teval-rmse:0.022062\n",
      "[101]\teval-rmse:0.022044\n",
      "[102]\teval-rmse:0.022027\n",
      "[103]\teval-rmse:0.022013\n",
      "[104]\teval-rmse:0.022\n",
      "[105]\teval-rmse:0.021988\n",
      "[106]\teval-rmse:0.021977\n",
      "[107]\teval-rmse:0.021967\n",
      "[108]\teval-rmse:0.021958\n",
      "[109]\teval-rmse:0.02195\n",
      "[110]\teval-rmse:0.021943\n",
      "[111]\teval-rmse:0.021937\n",
      "[112]\teval-rmse:0.021931\n",
      "[113]\teval-rmse:0.021926\n",
      "[114]\teval-rmse:0.021921\n",
      "[115]\teval-rmse:0.021917\n",
      "[116]\teval-rmse:0.021914\n",
      "[117]\teval-rmse:0.02191\n",
      "[118]\teval-rmse:0.021906\n",
      "[119]\teval-rmse:0.021904\n",
      "[120]\teval-rmse:0.021902\n",
      "[121]\teval-rmse:0.021899\n",
      "[122]\teval-rmse:0.021897\n",
      "[123]\teval-rmse:0.021896\n",
      "[124]\teval-rmse:0.021894\n",
      "[125]\teval-rmse:0.021892\n",
      "[126]\teval-rmse:0.021891\n",
      "[127]\teval-rmse:0.02189\n",
      "[128]\teval-rmse:0.021888\n",
      "[129]\teval-rmse:0.021887\n",
      "[130]\teval-rmse:0.021886\n",
      "[131]\teval-rmse:0.021884\n",
      "[132]\teval-rmse:0.021882\n",
      "[133]\teval-rmse:0.021881\n",
      "[134]\teval-rmse:0.02188\n",
      "[135]\teval-rmse:0.02188\n",
      "[136]\teval-rmse:0.021879\n",
      "[137]\teval-rmse:0.021879\n",
      "[138]\teval-rmse:0.021879\n",
      "[139]\teval-rmse:0.021879\n",
      "[140]\teval-rmse:0.021878\n",
      "[141]\teval-rmse:0.021877\n",
      "[142]\teval-rmse:0.021877\n",
      "[143]\teval-rmse:0.021878\n",
      "[144]\teval-rmse:0.021877\n",
      "[145]\teval-rmse:0.021877\n",
      "[146]\teval-rmse:0.021876\n",
      "[147]\teval-rmse:0.021877\n",
      "[148]\teval-rmse:0.021877\n",
      "[149]\teval-rmse:0.021877\n",
      "[150]\teval-rmse:0.021877\n",
      "[151]\teval-rmse:0.021876\n",
      "[152]\teval-rmse:0.021874\n",
      "[153]\teval-rmse:0.021874\n",
      "[154]\teval-rmse:0.021874\n",
      "[155]\teval-rmse:0.021874\n",
      "[156]\teval-rmse:0.021873\n",
      "[157]\teval-rmse:0.021874\n",
      "[158]\teval-rmse:0.021873\n",
      "[159]\teval-rmse:0.021873\n",
      "[160]\teval-rmse:0.021874\n",
      "[161]\teval-rmse:0.021873\n",
      "[162]\teval-rmse:0.021873\n",
      "[163]\teval-rmse:0.021874\n",
      "[164]\teval-rmse:0.021874\n",
      "[165]\teval-rmse:0.021874\n",
      "[166]\teval-rmse:0.021873\n",
      "[167]\teval-rmse:0.021874\n",
      "[168]\teval-rmse:0.021874\n",
      "[169]\teval-rmse:0.021873\n",
      "[170]\teval-rmse:0.021874\n",
      "[171]\teval-rmse:0.021874\n",
      "[172]\teval-rmse:0.021873\n",
      "[173]\teval-rmse:0.021873\n",
      "[174]\teval-rmse:0.021874\n",
      "[175]\teval-rmse:0.021874\n",
      "[176]\teval-rmse:0.021874\n",
      "[177]\teval-rmse:0.021874\n",
      "[178]\teval-rmse:0.021874\n",
      "[179]\teval-rmse:0.021874\n",
      "[180]\teval-rmse:0.021874\n",
      "[181]\teval-rmse:0.021874\n",
      "[182]\teval-rmse:0.021874\n",
      "[183]\teval-rmse:0.021875\n",
      "[184]\teval-rmse:0.021874\n",
      "[185]\teval-rmse:0.021875\n",
      "[186]\teval-rmse:0.021875\n",
      "[187]\teval-rmse:0.021876\n",
      "[188]\teval-rmse:0.021876\n",
      "[189]\teval-rmse:0.021876\n",
      "[190]\teval-rmse:0.021876\n",
      "[191]\teval-rmse:0.021876\n",
      "[192]\teval-rmse:0.021876\n",
      "[193]\teval-rmse:0.021876\n",
      "[194]\teval-rmse:0.021876\n",
      "[195]\teval-rmse:0.021876\n",
      "[196]\teval-rmse:0.021876\n",
      "[197]\teval-rmse:0.021876\n",
      "[198]\teval-rmse:0.021877\n",
      "[199]\teval-rmse:0.021877\n",
      "[200]\teval-rmse:0.021877\n",
      "[201]\teval-rmse:0.021876\n",
      "[202]\teval-rmse:0.021877\n",
      "[203]\teval-rmse:0.021877\n",
      "[204]\teval-rmse:0.021877\n",
      "[205]\teval-rmse:0.021877\n",
      "[206]\teval-rmse:0.021877\n",
      "Stopping. Best iteration:\n",
      "[156]\teval-rmse:0.021873\n",
      "\n",
      "-66.2281787762\n"
     ]
    }
   ],
   "source": [
    "pred, model=runXGBTest(X_train=X_train, y_train=y_train, X_test=X_test, num_rounds=500, test_size=.3)\n",
    "print(r2_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
