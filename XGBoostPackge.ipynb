{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import log_loss, mean_squared_error as mse, r2_score \n",
    "from sklearn.metrics.scorer import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def runXGB(X_train, y_train, X_test=None, num_class=1, feature_names=None, seed=0, num_rounds=1000, early_stopping_rounds=None):\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear', #'multi:softprob'\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1, #0.85, #like max_features\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'seed': seed,\n",
    "    'silent': 0,\n",
    "    'eval_metric': 'rmse' # \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "    }\n",
    "    \n",
    "    if num_class!=1:\n",
    "        params['num_class']=num_class\n",
    "\n",
    "    plst = list(params.items())\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    \n",
    "    model = xgb.train(plst, dtrain, num_boost_round=num_rounds, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    if X_test is not None:\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        pred = model.predict(dtest)\n",
    "        return pred, model\n",
    "    return None, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def runXGBShuffle(X_train, y_train, X_test, num_class=1, feature_names=None, seed=0, num_rounds=1000, test_size=.3, \\\n",
    "               early_stopping_rounds=None):\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear', #'multi:softprob'\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1, #0.85, #like max_features\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'seed': seed,\n",
    "    'silent': 0,\n",
    "    'eval_metric': 'rmse' # \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "    }\n",
    "    \n",
    "    if num_class!=1:\n",
    "        params['num_class']=num_class\n",
    "\n",
    "    plst = list(params.items())\n",
    "    X_dtrain, X_deval, y_dtrain, y_deval=train_test_split(X_train, y_train, random_state=seed, test_size=test_size)\n",
    "    dtrain = xgb.DMatrix(X_dtrain, y_dtrain)\n",
    "    deval = xgb.DMatrix(X_deval, y_deval)\n",
    "    watchlist = [(deval, 'eval')]\n",
    "    \n",
    "    model = xgb.train(plst, dtrain, num_rounds, watchlist, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    if X_test is not None:\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        pred = model.predict(dtest)\n",
    "        return pred, model\n",
    "    return None, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class xgbClass(object):\n",
    "    def __init__(self, eta=.1, subsample=.8, num_class=1, max_depth=5, seed=17, silent=0, eva_metric='mlogloss',\\\n",
    "                colsample_bytree=.8, objective='solfprob'):\n",
    "        self.params={\n",
    "        'objective' : objective, #'reg:linear','multi:softprob'\n",
    "        'subsample' : subsample,\n",
    "        'colsample_bytree' : colsample_bytree, #like max_features\n",
    "        'eta': eta,\n",
    "        'max_depth': max_depth,\n",
    "        'seed': seed,\n",
    "        'silent': silent,\n",
    "        'eval_metric': eva_metric#'rmse' \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "        }\n",
    "        \n",
    "        if num_class!=1:\n",
    "            self.params['num_class']=num_class\n",
    "        self.model=[]\n",
    "        \n",
    "    def fit(self, X_train, y_train, num_rounds=500, early_stopping_rounds=None):\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        self.model = xgb.train(self.params, dtrain, num_boost_round=num_rounds, early_stopping_rounds=early_stopping_rounds)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        return self.model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n=100000\n",
    "X=pd.DataFrame(np.random.randn(n,1))\n",
    "y=X.iloc[:,0]+.2*pd.Series(np.random.randn(n))\n",
    "X_train,y_train=X.iloc[:n/2], y.iloc[:n/2]\n",
    "X_test, y_test=X.iloc[n/2:], y.iloc[n/2:]\n",
    "\n",
    "# import kagglegym\n",
    "# env = kagglegym.make()\n",
    "# o = env.reset()\n",
    "# excl = [env.ID_COL_NAME, env.SAMPLE_COL_NAME, env.TARGET_COL_NAME, env.TIME_COL_NAME]\n",
    "# col = [c for c in o.train.columns if c not in excl]\n",
    "\n",
    "# O = pd.read_hdf('../input/train.h5')\n",
    "# d_mean= O[col].median(axis=0)\n",
    "\n",
    "# ymean_dict = dict(o.train.groupby([\"id\"])[\"y\"].median())\n",
    "\n",
    "# X_train=(O[col])[O.timestamp <= 905]\n",
    "# y_train=O.y[O.timestamp <= 905]\n",
    "# X_test=(O[col])[O.timestamp > 905]\n",
    "# y_test=O.y[O.timestamp > 905]\n",
    "# X_train=X_train.fillna(d_mean)\n",
    "# X_test=X_test.fillna(d_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959367862292\n"
     ]
    }
   ],
   "source": [
    "pred, model=runXGB(X_train=X_train, y_train=y_train, X_test=X_test, num_rounds=500)\n",
    "print(r2_score(pred, y_test))\n",
    "#-44.5409187933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.08444\n",
      "[1]\teval-rmse:1.03227\n",
      "[2]\teval-rmse:0.982866\n",
      "[3]\teval-rmse:0.93602\n",
      "[4]\teval-rmse:0.891542\n",
      "[5]\teval-rmse:0.849469\n",
      "[6]\teval-rmse:0.809562\n",
      "[7]\teval-rmse:0.771749\n",
      "[8]\teval-rmse:0.735948\n",
      "[9]\teval-rmse:0.702123\n",
      "[10]\teval-rmse:0.670081\n",
      "[11]\teval-rmse:0.639809\n",
      "[12]\teval-rmse:0.611173\n",
      "[13]\teval-rmse:0.584058\n",
      "[14]\teval-rmse:0.558446\n",
      "[15]\teval-rmse:0.534348\n",
      "[16]\teval-rmse:0.511632\n",
      "[17]\teval-rmse:0.490155\n",
      "[18]\teval-rmse:0.469953\n",
      "[19]\teval-rmse:0.45091\n",
      "[20]\teval-rmse:0.433076\n",
      "[21]\teval-rmse:0.416246\n",
      "[22]\teval-rmse:0.400447\n",
      "[23]\teval-rmse:0.3856\n",
      "[24]\teval-rmse:0.371737\n",
      "[25]\teval-rmse:0.358743\n",
      "[26]\teval-rmse:0.346619\n",
      "[27]\teval-rmse:0.335264\n",
      "[28]\teval-rmse:0.324691\n",
      "[29]\teval-rmse:0.314848\n",
      "[30]\teval-rmse:0.305699\n",
      "[31]\teval-rmse:0.297187\n",
      "[32]\teval-rmse:0.289293\n",
      "[33]\teval-rmse:0.281913\n",
      "[34]\teval-rmse:0.275099\n",
      "[35]\teval-rmse:0.268825\n",
      "[36]\teval-rmse:0.263026\n",
      "[37]\teval-rmse:0.257696\n",
      "[38]\teval-rmse:0.252784\n",
      "[39]\teval-rmse:0.248266\n",
      "[40]\teval-rmse:0.244088\n",
      "[41]\teval-rmse:0.240266\n",
      "[42]\teval-rmse:0.236781\n",
      "[43]\teval-rmse:0.233602\n",
      "[44]\teval-rmse:0.2307\n",
      "[45]\teval-rmse:0.228006\n",
      "[46]\teval-rmse:0.225546\n",
      "[47]\teval-rmse:0.223311\n",
      "[48]\teval-rmse:0.221309\n",
      "[49]\teval-rmse:0.219458\n",
      "[50]\teval-rmse:0.217782\n",
      "[51]\teval-rmse:0.21626\n",
      "[52]\teval-rmse:0.214858\n",
      "[53]\teval-rmse:0.213579\n",
      "[54]\teval-rmse:0.212427\n",
      "[55]\teval-rmse:0.211376\n",
      "[56]\teval-rmse:0.210447\n",
      "[57]\teval-rmse:0.209589\n",
      "[58]\teval-rmse:0.208824\n",
      "[59]\teval-rmse:0.208107\n",
      "[60]\teval-rmse:0.20746\n",
      "[61]\teval-rmse:0.206885\n",
      "[62]\teval-rmse:0.206359\n",
      "[63]\teval-rmse:0.205863\n",
      "[64]\teval-rmse:0.205439\n",
      "[65]\teval-rmse:0.205053\n",
      "[66]\teval-rmse:0.204696\n",
      "[67]\teval-rmse:0.204374\n",
      "[68]\teval-rmse:0.204092\n",
      "[69]\teval-rmse:0.20384\n",
      "[70]\teval-rmse:0.203616\n",
      "[71]\teval-rmse:0.203417\n",
      "[72]\teval-rmse:0.203233\n",
      "[73]\teval-rmse:0.203063\n",
      "[74]\teval-rmse:0.202908\n",
      "[75]\teval-rmse:0.202767\n",
      "[76]\teval-rmse:0.20263\n",
      "[77]\teval-rmse:0.202518\n",
      "[78]\teval-rmse:0.202406\n",
      "[79]\teval-rmse:0.202312\n",
      "[80]\teval-rmse:0.202226\n",
      "[81]\teval-rmse:0.202161\n",
      "[82]\teval-rmse:0.202101\n",
      "[83]\teval-rmse:0.202031\n",
      "[84]\teval-rmse:0.201967\n",
      "[85]\teval-rmse:0.201923\n",
      "[86]\teval-rmse:0.20188\n",
      "[87]\teval-rmse:0.201838\n",
      "[88]\teval-rmse:0.201795\n",
      "[89]\teval-rmse:0.201771\n",
      "[90]\teval-rmse:0.201753\n",
      "[91]\teval-rmse:0.201721\n",
      "[92]\teval-rmse:0.201691\n",
      "[93]\teval-rmse:0.201669\n",
      "[94]\teval-rmse:0.201654\n",
      "[95]\teval-rmse:0.201642\n",
      "[96]\teval-rmse:0.201625\n",
      "[97]\teval-rmse:0.201606\n",
      "[98]\teval-rmse:0.201594\n",
      "[99]\teval-rmse:0.201584\n",
      "[100]\teval-rmse:0.20157\n",
      "[101]\teval-rmse:0.201564\n",
      "[102]\teval-rmse:0.201561\n",
      "[103]\teval-rmse:0.201556\n",
      "[104]\teval-rmse:0.20155\n",
      "[105]\teval-rmse:0.201541\n",
      "[106]\teval-rmse:0.201536\n",
      "[107]\teval-rmse:0.201529\n",
      "[108]\teval-rmse:0.201524\n",
      "[109]\teval-rmse:0.201519\n",
      "[110]\teval-rmse:0.201519\n",
      "[111]\teval-rmse:0.201513\n",
      "[112]\teval-rmse:0.20151\n",
      "[113]\teval-rmse:0.201511\n",
      "[114]\teval-rmse:0.20151\n",
      "[115]\teval-rmse:0.201519\n",
      "[116]\teval-rmse:0.201524\n",
      "[117]\teval-rmse:0.201516\n",
      "[118]\teval-rmse:0.201515\n",
      "[119]\teval-rmse:0.201522\n",
      "[120]\teval-rmse:0.201523\n",
      "[121]\teval-rmse:0.20153\n",
      "[122]\teval-rmse:0.201524\n",
      "[123]\teval-rmse:0.201526\n",
      "[124]\teval-rmse:0.201532\n",
      "[125]\teval-rmse:0.201533\n",
      "[126]\teval-rmse:0.201531\n",
      "[127]\teval-rmse:0.201532\n",
      "[128]\teval-rmse:0.201532\n",
      "[129]\teval-rmse:0.201537\n",
      "[130]\teval-rmse:0.201538\n",
      "[131]\teval-rmse:0.201541\n",
      "[132]\teval-rmse:0.201542\n",
      "[133]\teval-rmse:0.201543\n",
      "[134]\teval-rmse:0.201546\n",
      "[135]\teval-rmse:0.20155\n",
      "[136]\teval-rmse:0.201546\n",
      "[137]\teval-rmse:0.201556\n",
      "[138]\teval-rmse:0.201559\n",
      "[139]\teval-rmse:0.201566\n",
      "[140]\teval-rmse:0.20157\n",
      "[141]\teval-rmse:0.201577\n",
      "[142]\teval-rmse:0.201582\n",
      "[143]\teval-rmse:0.201579\n",
      "[144]\teval-rmse:0.201582\n",
      "[145]\teval-rmse:0.201586\n",
      "[146]\teval-rmse:0.201587\n",
      "[147]\teval-rmse:0.201591\n",
      "[148]\teval-rmse:0.201602\n",
      "[149]\teval-rmse:0.201602\n",
      "[150]\teval-rmse:0.201606\n",
      "[151]\teval-rmse:0.201605\n",
      "[152]\teval-rmse:0.201612\n",
      "[153]\teval-rmse:0.201617\n",
      "[154]\teval-rmse:0.201616\n",
      "[155]\teval-rmse:0.201619\n",
      "[156]\teval-rmse:0.201618\n",
      "[157]\teval-rmse:0.201618\n",
      "[158]\teval-rmse:0.201625\n",
      "[159]\teval-rmse:0.201625\n",
      "[160]\teval-rmse:0.201633\n",
      "[161]\teval-rmse:0.201626\n",
      "[162]\teval-rmse:0.201636\n",
      "[163]\teval-rmse:0.201637\n",
      "[164]\teval-rmse:0.201641\n",
      "[165]\teval-rmse:0.20165\n",
      "[166]\teval-rmse:0.201652\n",
      "[167]\teval-rmse:0.201652\n",
      "[168]\teval-rmse:0.201663\n",
      "[169]\teval-rmse:0.201664\n",
      "[170]\teval-rmse:0.201662\n",
      "[171]\teval-rmse:0.201665\n",
      "[172]\teval-rmse:0.201665\n",
      "[173]\teval-rmse:0.20166\n",
      "[174]\teval-rmse:0.201665\n",
      "[175]\teval-rmse:0.201671\n",
      "[176]\teval-rmse:0.201679\n",
      "[177]\teval-rmse:0.201683\n",
      "[178]\teval-rmse:0.201693\n",
      "[179]\teval-rmse:0.201699\n",
      "[180]\teval-rmse:0.201699\n",
      "[181]\teval-rmse:0.201694\n",
      "[182]\teval-rmse:0.201701\n",
      "[183]\teval-rmse:0.201703\n",
      "[184]\teval-rmse:0.201711\n",
      "[185]\teval-rmse:0.201717\n",
      "[186]\teval-rmse:0.201722\n",
      "[187]\teval-rmse:0.201725\n",
      "[188]\teval-rmse:0.201728\n",
      "[189]\teval-rmse:0.201738\n",
      "[190]\teval-rmse:0.201747\n",
      "[191]\teval-rmse:0.201745\n",
      "[192]\teval-rmse:0.201744\n",
      "[193]\teval-rmse:0.201739\n",
      "[194]\teval-rmse:0.201737\n",
      "[195]\teval-rmse:0.201735\n",
      "[196]\teval-rmse:0.201739\n",
      "[197]\teval-rmse:0.201741\n",
      "[198]\teval-rmse:0.201742\n",
      "[199]\teval-rmse:0.201751\n",
      "[200]\teval-rmse:0.201752\n",
      "[201]\teval-rmse:0.20175\n",
      "[202]\teval-rmse:0.201756\n",
      "[203]\teval-rmse:0.201754\n",
      "[204]\teval-rmse:0.201762\n",
      "[205]\teval-rmse:0.201763\n",
      "[206]\teval-rmse:0.201765\n",
      "[207]\teval-rmse:0.201771\n",
      "[208]\teval-rmse:0.201782\n",
      "[209]\teval-rmse:0.20178\n",
      "[210]\teval-rmse:0.201777\n",
      "[211]\teval-rmse:0.201782\n",
      "[212]\teval-rmse:0.201785\n",
      "[213]\teval-rmse:0.201787\n",
      "[214]\teval-rmse:0.201783\n",
      "[215]\teval-rmse:0.20178\n",
      "[216]\teval-rmse:0.201782\n",
      "[217]\teval-rmse:0.201787\n",
      "[218]\teval-rmse:0.201796\n",
      "[219]\teval-rmse:0.201798\n",
      "[220]\teval-rmse:0.201795\n",
      "[221]\teval-rmse:0.201792\n",
      "[222]\teval-rmse:0.201794\n",
      "[223]\teval-rmse:0.20179\n",
      "[224]\teval-rmse:0.201789\n",
      "[225]\teval-rmse:0.201785\n",
      "[226]\teval-rmse:0.201789\n",
      "[227]\teval-rmse:0.201786\n",
      "[228]\teval-rmse:0.20179\n",
      "[229]\teval-rmse:0.201791\n",
      "[230]\teval-rmse:0.201797\n",
      "[231]\teval-rmse:0.201798\n",
      "[232]\teval-rmse:0.201798\n",
      "[233]\teval-rmse:0.201797\n",
      "[234]\teval-rmse:0.201797\n",
      "[235]\teval-rmse:0.2018\n",
      "[236]\teval-rmse:0.2018\n",
      "[237]\teval-rmse:0.201809\n",
      "[238]\teval-rmse:0.201815\n",
      "[239]\teval-rmse:0.201818\n",
      "[240]\teval-rmse:0.201823\n",
      "[241]\teval-rmse:0.201826\n",
      "[242]\teval-rmse:0.201826\n",
      "[243]\teval-rmse:0.201829\n",
      "[244]\teval-rmse:0.201832\n",
      "[245]\teval-rmse:0.20183\n",
      "[246]\teval-rmse:0.201844\n",
      "[247]\teval-rmse:0.20185\n",
      "[248]\teval-rmse:0.201854\n",
      "[249]\teval-rmse:0.201858\n",
      "[250]\teval-rmse:0.20186\n",
      "[251]\teval-rmse:0.201857\n",
      "[252]\teval-rmse:0.20186\n",
      "[253]\teval-rmse:0.20186\n",
      "[254]\teval-rmse:0.201862\n",
      "[255]\teval-rmse:0.201867\n",
      "[256]\teval-rmse:0.201869\n",
      "[257]\teval-rmse:0.201876\n",
      "[258]\teval-rmse:0.201876\n",
      "[259]\teval-rmse:0.201878\n",
      "[260]\teval-rmse:0.201882\n",
      "[261]\teval-rmse:0.20188\n",
      "[262]\teval-rmse:0.201888\n",
      "[263]\teval-rmse:0.201885\n",
      "[264]\teval-rmse:0.201889\n",
      "[265]\teval-rmse:0.201888\n",
      "[266]\teval-rmse:0.201892\n",
      "[267]\teval-rmse:0.201891\n",
      "[268]\teval-rmse:0.201895\n",
      "[269]\teval-rmse:0.201896\n",
      "[270]\teval-rmse:0.201902\n",
      "[271]\teval-rmse:0.201905\n",
      "[272]\teval-rmse:0.201905\n",
      "[273]\teval-rmse:0.201908\n",
      "[274]\teval-rmse:0.201911\n",
      "[275]\teval-rmse:0.201916\n",
      "[276]\teval-rmse:0.201928\n",
      "[277]\teval-rmse:0.201924\n"
     ]
    }
   ],
   "source": [
    "pred, model=runXGBShuffle(X_train=X_train, y_train=y_train, X_test=X_test, num_rounds=500, test_size=.3)\n",
    "print(r2_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model=xgbClass(objective='reg:linear', eva_metric='rmse')\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "print(r2_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
